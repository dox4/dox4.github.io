---
layout: post
title:  high concurrency, what, how and why
date:   2020-11-24 16:02:31 +0800
author: dox4
categories: notes
tags: high concurrency
---

写一点关于高并发的简单想法。

## what is high concurrency

在 **to B** 的业务中，很少会见到高并发的场景。企业服务的用户量基本上不会太大，并发量也就上不去。

高并发的场景一般发生在 **to C** 的场景下，最常见的，比如说**秒杀**系统。这是一个典型的高并发场景，人为的將用户请求集中到某个特定的时间点。

从商业逻辑上考虑，秒杀自然有其商业价值。若从技术上考虑的话，我想，可能有准备的大战，会比不经意的遭遇战更容易让人应对吧。

起码我知道今晚九点秒杀开始，我可以先启动几台备用服务器部署到集群里，对吧。

这样当大量的用户请求涌入服务器的时候，不至于直接崩了。

当然，真正去解决高并发的问题，不是加几台服务器就可以的。

## how to deal with high concurrency

关于高并发场景的应对，首先应该分个类：
1. 并发读；
2. 并发写。

接下来一个一个说。

**并发读**显然是比并发写更容易应对的。而上边说的**秒杀**，则是一个**并发写**的场景。

并发读的通用解决方案其实说起来只有两个，就是**缓存**和**分流**。

静态资源缓存在服务器上，请求过来读过去就好了——当然实际上并没有这么简单。

例如，流行的 `JavaScript` 库会使用 `CDN (Content Delivery Network)` 技术分发自己的代码，以保证用户的使用体验。

这是在缓存的基础上进行**分流**。

一方面是因为各地的网络情况不同，使用近距离的 `CDN` 服务器可以提高用户的加载速度；另一方面，即使是并发读，对于服务器来说也是有 `IO` 压力的。哪怕是内存 `IO`，读得太多也会提高服务器负载，而使用 `CDN` 分发静态资源可以平衡各地的服务器压力。

当然，作为一个分布式系统，`CDN` 服务器也会涉及到数据一致性的问题。

数据一致性是使用分布式系统必然会带来的问题，一个简单的解决方案是设置静态资源的过期时间，资源过期了就重新拉取静态资源。当然同一技术落地可以有不同的实现，不过数据一致性不是本文的重点，先点到为止吧。

动态资源的并发读对于服务端来说可能会更复杂一些。比如知乎的首页，那当然是一个动态页面，每次刷新都会拿到一个不同的**问题/答案**列表。

其他符合个性化定制和推送的网站、客户端首页也是类似的。

我不知道知乎实际上是怎么解决的，不过我观察到，如果使用未登录的用户查看移动端首页，短时间内刷新拿到的内容是一样的。

所以我猜知乎可能维护了一个默认的推荐列表，定时更新，在两次更新中间的时间段去访问这个默认推荐列表，拿到的数据就是一样的。

于是一个动态资源被维护成了静态资源。

那么为了减轻服务器压力，这个方案也可以推广到已登录用户身上。尽管已登录用户每次刷新都应该拿到不同的推荐列表，但这并不妨碍知乎等网站可以把个性化定制的动态推荐实现成为静态资源。

例如，根据用户行为（关注、浏览、点赞、反对等）將用户分组，比如分成十万个组，每个组中的用户拿到的推荐列表是一样的。

这样维护一个动态页面的功能就变成了维护十万个静态页面。即使考虑到有些用户会不停的刷新页面（比如我），只要这些用户的比例不大，也不会对服务器有过大的冲击。如果也要解决这个问题的话，把每组中的单一静态页面改成静态页面队列可以作为一个备选的解决方案。

并发读就先到这，再聊一聊并发写。

并发写涉及到的业务就更复杂了。而我实在没有相关的经验，所以还是拿上边那个秒杀功能举例吧。

通过对单一功能点的思考，找到一些通用的解决方案，这是我解决业务问题的一贯做法。

对于并发写最快糙猛的解决办法就是堆机器，「只要我的机器性能够好，高并发就打不垮我」。

但是相对于低频次的秒杀活动，更多的时间中并发量没那么高，于是那些机器就浪费了。所以这个解决方案不太好用。

在不堆机器的情况下，想要扛住高并发就需要考虑其他方案了。

堆机器换成专业一点的名词应该是「分布式」系统，这与并发读中的**分流**的逻辑是一致的。

在分流无法满足需要的情况下，再细致地考虑一下并发写的业务场景，以及并发读中的另外一个工具**缓存**能不能应用在这个场景之下。

对于并发用户来说，他们希望的尽快看到自己的秒杀是不是成功了，如果成功了则希望尽快看到订单的结果。

但对于服务端来说，订单系统并不是这么简单的。除了查询库存、用户校验等用户敏感的步骤之外，系统本身还有很多其他的动作需要在一个请求中完成，比如日志记录、数据库读写、安全检查、银行对账（？）之类的。

那么并发请求的模型可能是这样的：

```plaintext
            -----------------
            | request queue |
            -----------------
           /        |        \
------------   ------------   ------------
| server 1 |   | server 2 |   | server 3 |
------------   ------------   ------------
|  step 1  |   |  step 1  |   |  step 1  |
|  step 2  |   |  step 2  |   |  step 2  | ...
|  step 3  |   |  step 3  |   |  step 3  |
|  step 4  |   |  step 4  |   |  step 4  |
|  step 5  |   |  step 5  |   |  step 5  |
|----------|   |----------|   |----------|
      |             |              |
 ----------------------------------------
 |           response to user           |
 ----------------------------------------
```

对于用户来说，这些请求都是要求实时性的，但对于系统来说，在一个请求的过程中，并不是所有步骤都要求实时性的，比如记录日志这件事。

于是，將那些不要求实时性的步骤拎出来，假设上述模型中的`step 3 ~ step 5` 是不要求实时性的，可以变成下面这样：
```plaintext
            -----------------                       -------------------
            | request queue |                    /--| operation queue |
            -----------------                    |  -------------------
           /        |        \                   |           |
------------   ------------   ------------       |     ------------
| server 1 |   | server 2 |   | server 3 |       |     | server 4 |
------------   ------------   ------------       |     |-----------
|  step 1  |   |  step 1  |   |  step 1  |       |     |  step 3  | ...
|  step 2  |   |  step 2  |   |  step 2  | ...   |     |  step 4  |
|----------|   |----------|   |----------|       |     |  step 5  |
      |             |              |             |     |----------|     
      |-------------|--------------|-------------/
      |             |              |
 ----------------------------------------
 |           response to user           |
 ----------------------------------------
```

如果五个 `step` 的耗时一样，那么用户感知的响应时间就降低到接近原来的百分之四十。

这个解决问题的思路也不是解决高并发问题独有的，几年前在讨论 `iOS` 为什么会比 `android` 系统流畅的时候，其中一个原因就是，`iOS` 的渲染策略是用户界面优先渲染，其他的动作在后台跑，这样可能会拉长应用程序的启动时间，但用户已经看到了应用程序的启动动画，得到了部分反馈，于是就不会对应用程序启动时间那么敏感。而当时的 `android` 则“老老实实”的启动应用程序，感知到的就是应用程序启动很慢。

当然现在 `android` 的应用程序走向了另一个方向，不管启动是不是迅速，先放几秒的广告，用户就只会抱怨广告，而不会抱怨应用程序启动慢了。

简直鬼才。

话说回来，上述的做法也不是万无一失的。尽管在 `step 1 & 2` 中已经确认了用户请求的最终状态，但成功的请求也不是一定就会成功。极端条件下，如果数据没有成功入库，服务器断电，数据就丢失了。这当然是不可接受的，所以也必须要有另外的方案保证这一点。这也不是本文的重点，所以就不细说了。

这让我想起我曾经遇到的一个问题。

我司的业务经常会处理表格数据，由于某种设计上的取舍，对于用户看到的一个 `100 * 100` 的表格，对应数据库中可能不是 `100` 条数据，而是 `100 * 100 = 10000` 条数据。

在这种设计下的某个业务节点上就遇到了一个一次性入库 `170000` 条数据的特殊情况。按照上边的思路，后端其实只需要检查完数据的正确性就可以返回给用户成功的信息了，入库并不是必须现在做的。將表格数据暂时缓存在服务器内存中，并不影响用户的后续操作。

但最终的解决方案并不是这样的，由于某种设计上的取舍，数据必须入库以后才能给用户反馈。所以最终的解决方案是加入了一张临时表，`170000` 的业务数据在临时表中只有 `1700` 行，这样的插入延迟是可以接受的。正式入库的任务则在后台慢慢跑。

这个临时表所起到的也是缓存的作用。

关于并发写的应对措施，这只是一个大致的思路。更细致的解决方案我想还是需要更具体的信息，我没有遇到过相当的业务场景，这么分析来分析去总有一种不踏实的感觉。在具体的业务场景中去处理问题才有意义，很多问题的解决方案都是和业务强相关的。

## why, for what?

其实在第二部分聊怎么解决的时候，差不多就已经说出了 `why`。这也是我个人解决问题的一贯方式，先把问题的原因搞清楚，再针对性的去解决，这样的解决方案才会给人安全感。

有些时候遇到的问题可能改个配置，注释掉某行代码就神奇的消失了，虽然暂时解决了问题，但因为不知道其所以然，所以总觉得还是不够。

然而，但是。

